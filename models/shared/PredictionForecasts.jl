module PredictionForecasts

# Create a bunch of Forecast structs whose data is the
# predictions generated by some prediction model applied
# to an existing base forecast (e.g. HREF).
#
# get_feature_engineered_data will use the underlying winds to
# generate the spatial means and gradients of the probability.

import MemoryConstrainedTreeBoosting

push!(LOAD_PATH, (@__DIR__) * "/../../lib")

import Forecasts
import Grids
import Inventories
import ForecastCombinators

push!(LOAD_PATH, (@__DIR__) * "/../shared")
import FeatureEngineeringShared

function weighted_prediction_between_models_at_different_forecast_hours(forecast, data, low_hour, high_hour, low_hour_predict, high_hour_predict)
  high_weight = ((forecast.forecast_hour-low_hour) / Float32(high_hour - low_hour)) :: Float32
  (1 - high_weight) .* low_hour_predict(data) .+ high_weight .* high_hour_predict(data)
end

# calibrations should be ordered
function calibrated_forecasts(base_forecasts, calibrations; model_name = nothing)

  ratio_between(x, lo, hi) = (x - lo) / (hi - lo)

  # Add 0,0 and 1,1 and make sure they're Float32
  calibrations =
    map(calibrations) do calibration
      calibration = [(0f0,0f0); calibration; (1f0,1f0)]
      map(calib -> Float32.(calib), calibration)
    end :: Vector{Vector{Tuple{Float32,Float32}}}

  # Mutates out
  function calibrate!(out, base_data, thresholds, feature_i)
    Threads.@threads for i in 1:size(base_data,1)
      x = base_data[i,feature_i]
      for k in 2:length(thresholds)
        lo_spc, lo_thres = thresholds[k-1]
        hi_spc, hi_thres = thresholds[k]
        if x < hi_thres || k == length(thresholds)
          ratio = ratio_between(x, lo_thres, hi_thres)
          out[i,feature_i] = lo_spc + ratio * (hi_spc - lo_spc)
          break
        end
      end
    end
  end

  data_transformer(base_forecast, base_data) = begin
    out = Array{Float32}(undef, size(base_data))

    for feature_i in 1:size(base_data, 2)
      thresholds = calibrations[feature_i]
      calibrate!(out, base_data, thresholds, feature_i)
    end

    out
  end

  ForecastCombinators.map_forecasts(base_forecasts; data_transformer = data_transformer, model_name = model_name)
end


# models is an array of (event_name, var_name, model_predict)
# model_predict takes forecast, data
# output is length(models) features, one for each model
function simple_prediction_forecasts(base_forecasts, models; model_name = nothing)

  inventory_transformer(base_forecast, base_inventory) =
    map(models) do (event_name, var_name, model_predict)
      Inventories.InventoryLine(
        "",                                         # message_dot_submessage :: String # "3" or "3.2"
        "",                                         # position_str           :: String # "956328"
        base_inventory[1].date_str,                 # date_str               :: String # "d=2018062900"
        var_name,                                   # abbrev                 :: String # "CAPE"
        "calculated",                               # level                  :: String # "180-0 mb above ground"
        "$(base_forecast.forecast_hour) hour fcst", # forecast_hour_str      :: String # "7 hour fcst" or "6-hour acc fcst" or "11-12 hour acc fcst" or "11-12 hour ave fcst"  or "11-12 hour max fcst"
        "calculated_prob",                          # misc                   :: String # "wt ens mean" or "prob >2.54"
        ""                                          # feature_engineering    :: String # "" or "25mi mean" or "100mi forward grad" etc
      )
    end

  data_transformer(base_forecast, base_data) = begin
    data_count    = size(base_data, 1)
    feature_count = length(models)
    out = Array{Float32}(undef, (data_count, feature_count))

    for i in 1:length(models)
      event_name, var_name, model_predict = models[i]
      out[:, i] = Float32.(model_predict(base_forecast, base_data))
    end

    out
  end

  ForecastCombinators.map_forecasts(base_forecasts; inventory_transformer = inventory_transformer, data_transformer = data_transformer, model_name = model_name)
end

# Prediction forecast modified with no blur, each of the blur radii, and the forecast hour
# So 1+length(blur_radii)+1 features.
function with_blurs_and_forecast_hour(prediction_forecasts, blur_radii; model_name = nothing)
  grid = prediction_forecasts[1].grid

  blur_radii_grid_is = map(miles -> Grids.radius_grid_is(grid, miles), Float64.(blur_radii))


  inventory_transformer(base_forecast, base_inventory) = begin

    new_inventory = []

    for i in 1:length(base_inventory)
      no_blur_line = base_inventory[i]
      push!(new_inventory, no_blur_line)

      for miles in blur_radii
        push!(new_inventory, Inventories.revise_with_feature_engineering(no_blur_line, "$(miles)mi mean"))
      end
    end

    push!(new_inventory, Inventories.InventoryLine("", "", base_inventory[1].date_str, "forecast_hour", "calculated", "hour fcst", "", ""))

    new_inventory
  end

  data_transformer(base_forecast, base_data) = begin
    point_count, prediction_count = size(base_data)

    out_feature_count = (1 + length(blur_radii)) * prediction_count + 1

    out = Array{Float32}(undef, (point_count, out_feature_count))

    out_feature_i = 0

    for prediction_i in 1:prediction_count
      no_blur_data = @view base_data[:, prediction_i]

      out_feature_i += 1
      out[:, out_feature_i] = no_blur_data

      for blur_i in 1:length(blur_radii)
        out_feature_i += 1
        out[:, out_feature_i] = FeatureEngineeringShared.meanify_threaded(no_blur_data, blur_radii_grid_is[blur_i])
      end
    end

    out_feature_i += 1
    out[:, out_feature_i] .= Float32(base_forecast.forecast_hour)

    @assert out_feature_i == out_feature_count

    out
  end

  ForecastCombinators.map_forecasts(prediction_forecasts; inventory_transformer = inventory_transformer, data_transformer = data_transformer, model_name = model_name)
end

# Prediction forecast blurred based on forecast hour.
# Linear combination of the two blur results s.t. at the near (lo) forecast hour only the first blur is used and
# at the far (hi) forecast hour, only the second blur is used.
# 1 resulting features: blurred result
function blurred(prediction_forecasts, forecast_hour_range, blur_grid_is; model_name = nothing)

  inventory_transformer(base_forecast, base_inventory) =
    map(base_inventory) do no_blur_line
      Inventories.revise_with_feature_engineering(no_blur_line, "blurred")
    end

  data_transformer(base_forecast, base_data) = begin
    point_count, prediction_count = size(base_data)

    out = Array{Float32}(undef, (point_count, prediction_count))

    for prediction_i in 1:prediction_count
      blur_lo_grid_is, blur_hi_grid_is = blur_grid_is[prediction_i]

      no_blur_data = @view base_data[:, prediction_i]
      blur_lo_data = FeatureEngineeringShared.meanify_threaded(no_blur_data, blur_lo_grid_is)
      blur_hi_data = FeatureEngineeringShared.meanify_threaded(no_blur_data, blur_hi_grid_is)

      forecast_hour = Float32(base_forecast.forecast_hour)
      lo_hour = Float32(forecast_hour_range.start)
      hi_hour = Float32(forecast_hour_range.stop)
      forecast_ratio = (forecast_hour - lo_hour) * (1f0/(hi_hour-lo_hour))
      one_minus_forecast_ratio = 1f0 - forecast_ratio

      Threads.@threads for i in 1:point_count
        out[i, prediction_i] = blur_lo_data[i] * one_minus_forecast_ratio + blur_hi_data[i] * forecast_ratio
      end
    end

    out
  end

  ForecastCombinators.map_forecasts(prediction_forecasts; inventory_transformer = inventory_transformer, data_transformer = data_transformer, model_name = model_name)
end


# models is array of (_, var_name, ...) tuples
function daily_and_fourhourly_accumulators(hourly_prediction_forecasts, models; module_name)
  event_types_count = length(models)

  day_hourly_predictions, day2_hourly_predictions, fourhourly_predictions = ForecastCombinators.gather_daily_and_fourhourly(hourly_prediction_forecasts)

  hourlies_to_accs_inventory_transformer(day_or_four_hour_str) = (base_forecast, base_inventory) -> begin
    out = Inventories.InventoryLine[]
    for model_i in 1:event_types_count
      _, var_name = models[model_i]
      push!(out, Inventories.InventoryLine("", "", base_inventory[1].date_str, "independent events total $(var_name)", "calculated", "$day_or_four_hour_str fcst", "", ""))
      push!(out, Inventories.InventoryLine("", "", base_inventory[1].date_str, "highest hourly $(var_name)",           "calculated", "$day_or_four_hour_str fcst", "", ""))
    end
    out
  end

  hourlies_to_accs_data_transformer(base_forecast, base_data) = begin
    point_count, base_feature_count = size(base_data)
    hours_count = div(base_feature_count, event_types_count)

    out = Array{Float32}(undef, (point_count, 2 * event_types_count))

    Threads.@threads for i in 1:point_count
      for event_i in 1:event_types_count
        prob_no_tor = 1.0
        for hour_i in 1:hours_count
          prob_no_tor *= 1.0 - Float64((@view base_data[i, event_i:event_types_count:base_feature_count])[hour_i])
        end
        out[i, event_i*2 - 1] = Float32(1.0 - prob_no_tor)
        out[i, event_i*2    ] = maximum(@view base_data[i, event_i:event_types_count:base_feature_count])

        # sorted_probs = sort((@view base_data[i, event_i:event_types_count:base_feature_count]); rev = true)
        # out[i,2] = sorted_probs[1]
        # out[i,3] = sorted_probs[2]
        # out[i,4] = sorted_probs[3]
        # out[i,5] = sorted_probs[4]
        # out[i,6] = sorted_probs[5]
        # out[i,7] = sorted_probs[6]
      end
    end
    out
  end

  # Caching barely helps load times, so we don't do it

  forecasts_day_accumulators        = ForecastCombinators.map_forecasts(day_hourly_predictions;  inventory_transformer = hourlies_to_accs_inventory_transformer("day"),    data_transformer = hourlies_to_accs_data_transformer, model_name = "Day_severe_probability_accumulators_from_$(module_name)_hours")
  forecasts_day2_accumulators       = ForecastCombinators.map_forecasts(day2_hourly_predictions; inventory_transformer = hourlies_to_accs_inventory_transformer("day"),    data_transformer = hourlies_to_accs_data_transformer, model_name = "Day2_severe_probability_accumulators_from_$(module_name)_hours")
  forecasts_fourhourly_accumulators = ForecastCombinators.map_forecasts(fourhourly_predictions;  inventory_transformer = hourlies_to_accs_inventory_transformer("4 hour"), data_transformer = hourlies_to_accs_data_transformer, model_name = "Four-hourly_severe_probability_accumulators_from_$(module_name)_hours")

  (forecasts_day_accumulators, forecasts_day2_accumulators, forecasts_fourhourly_accumulators)
end

# Turn the total and max period (day or four-hourly) probs into a combined calibrated prob, based on bins and logistic regression across overlapping bin-pairs
#
# models is array of (model_name, var_name, ...) tuples
function period_forecasts_from_accumulators(forecasts_period_accumulators, model_name_to_bins, model_name_to_bins_logistic_coeffs, models; module_name, period_name)

  ratio_between(x, lo, hi) = (x - lo) / (hi - lo)

  σ(x) = 1.0f0 / (1.0f0 + exp(-x))

  logit(p) = log(p / (one(p) - p))

  # array of (model_name, var_name, predict)
  period_models = map(1:length(models)) do model_i
    model_name, var_name = models[model_i]

    predict(forecast, data) = begin
      total_prob_ŷs = @view data[:, model_i*2 - 1]
      max_hourly_ŷs = @view data[:, model_i*2]

      out = Array{Float32}(undef, length(total_prob_ŷs))

      bin_maxes            = model_name_to_bins[model_name]
      bins_logistic_coeffs = model_name_to_bins_logistic_coeffs[model_name]

      @assert length(bin_maxes) == length(bins_logistic_coeffs) + 1

      predict_one(coeffs, total_prob_ŷ, max_hourly_ŷ) = σ(coeffs[1]*logit(total_prob_ŷ) + coeffs[2]*logit(max_hourly_ŷ) + coeffs[3])

      Threads.@threads for i in 1:length(total_prob_ŷs)
        total_prob_ŷ = total_prob_ŷs[i]
        max_hourly_ŷ = max_hourly_ŷs[i]
        if total_prob_ŷ <= bin_maxes[1]
          # Bin 1-2 predictor only
          ŷ = predict_one(bins_logistic_coeffs[1], total_prob_ŷ, max_hourly_ŷ)
        elseif total_prob_ŷ > bin_maxes[length(bin_maxes) - 1]
          # Bin 3-4 predictor only
          ŷ = predict_one(bins_logistic_coeffs[length(bins_logistic_coeffs)], total_prob_ŷ, max_hourly_ŷ)
        else
          # Overlapping bins
          higher_bin_i = findfirst(bin_max -> total_prob_ŷ <= bin_max, bin_maxes)
          lower_bin_i  = higher_bin_i - 1
          coeffs_higher_bin = bins_logistic_coeffs[higher_bin_i]
          coeffs_lower_bin  = bins_logistic_coeffs[lower_bin_i]

          # Bin 1-2 and 2-3 predictors
          ratio = ratio_between(total_prob_ŷ, bin_maxes[lower_bin_i], bin_maxes[higher_bin_i])
          ŷ = ratio*predict_one(coeffs_higher_bin, total_prob_ŷ, max_hourly_ŷ) + (1f0 - ratio)*predict_one(coeffs_lower_bin, total_prob_ŷ, max_hourly_ŷ)
        end
        out[i] = ŷ
      end

      out
    end

    (model_name, var_name, predict)
  end

  PredictionForecasts.simple_prediction_forecasts(forecasts_period_accumulators, period_models; model_name = "$(module_name)_$(period_name)_severe_probabilities")
end









# "models" here is list of (event_name, var_name, ...) tuples
# "gated_models" here is list of (gated_event_name, orig_event_name, gate_event_name) tuples
# adds the gated predictions to the end
function added_gated_predictions(base_forecasts, orig_models, gated_models; model_name = nothing)

  inventory_transformer(base_forecast, base_inventory) = begin
    gated_inventory = map(gated_models) do (gated_event_name, orig_event_name, gate_event_name)
      _, var_name = filter(m -> m[1] == orig_event_name, orig_models)[1]
      Inventories.InventoryLine(
        "",                                         # message_dot_submessage :: String # "3" or "3.2"
        "",                                         # position_str           :: String # "956328"
        base_inventory[1].date_str,                 # date_str               :: String # "d=2018062900"
        var_name,                                   # abbrev                 :: String # "CAPE"
        "calculated",                               # level                  :: String # "180-0 mb above ground"
        "$(base_forecast.forecast_hour) hour fcst", # forecast_hour_str      :: String # "7 hour fcst" or "6-hour acc fcst" or "11-12 hour acc fcst" or "11-12 hour ave fcst"  or "11-12 hour max fcst"
        "calculated_prob",                          # misc                   :: String # "wt ens mean" or "prob >2.54"
        "gated by $gate_event_name"                 # feature_engineering    :: String # "" or "25mi mean" or "100mi forward grad" etc
      )
    end

    [base_inventory; gated_inventory]
  end

  data_transformer(base_forecast, base_data) = begin
    data_count    = size(base_data, 1)
    feature_count = length(orig_models) + length(gated_models)
    out = Array{Float32}(undef, (data_count, feature_count))

    @inbounds Threads.@threads for i in 1:length(base_data)
      out[i] = base_data[i]
    end

    Threads.@threads for j in 1:length(gated_models)
      gated_event_name, orig_event_name, gate_event_name = gated_models[j]
      orig_model_i = findfirst(m -> m[1] == orig_event_name, orig_models)
      gate_model_i = findfirst(m -> m[1] == gate_event_name, orig_models)

      out[:, length(orig_models) + j] .= min.((@view out[:, orig_model_i]), (@view out[:, gate_model_i]))
    end

    out
  end

  ForecastCombinators.map_forecasts(base_forecasts; inventory_transformer = inventory_transformer, data_transformer = data_transformer, model_name = model_name)
end



end # module PredictionForecasts
